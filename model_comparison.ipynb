{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def load_conduct_data(conduct_path=\"E:/code\"):\n",
    "    csv_path = os.path.join(conduct_path, \"foam1.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "import keras.backend as K\n",
    "def r2(y_test, y_pred):\n",
    "    a = K.square(y_pred - y_test)\n",
    "    b = K.sum(a)\n",
    "    c = K.mean(y_test)\n",
    "    d = K.square(y_test - c)\n",
    "    e = K.sum(d)\n",
    "    f = 1 - b/e\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from time import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVR\n",
    "np.random.seed(30)\n",
    "tf.random.set_seed(30)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5,shuffle=True, random_state=None)\n",
    "conduct = load_conduct_data()\n",
    "c = np.array(conduct)\n",
    "X = c[:,:131]\n",
    "y = c[:,131:132]\n",
    "X = preprocessing.scale(X)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "   X, y,random_state = 32, shuffle = True)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "   X_train_full, y_train_full,random_state = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "r2=[]\n",
    "mape=[]\n",
    "mae = []\n",
    "mse = []\n",
    "acc = []\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    reg = GradientBoostingRegressor(random_state=0)\n",
    "    reg.fit(X_train, y_train)\n",
    "    gbr_pre = reg.predict(X_test)\n",
    "    yyy=gbr_pre.reshape(len(y_test),1) - y_test\n",
    "    zzz = yyy / y_test\n",
    "    cnt = 0\n",
    "    for i in zzz:\n",
    "        if i < 0.05 and i > -0.05:\n",
    "            cnt += 1\n",
    "    acc_GBR = cnt / len(zzz)\n",
    "    r2.append(r2_score(y_test,gbr_pre))\n",
    "    mape.append(mean_absolute_percentage_error(y_test,gbr_pre))\n",
    "    mae.append(mean_absolute_error(y_test,gbr_pre))\n",
    "    mse.append(mean_squared_error(y_test,gbr_pre))\n",
    "    acc.append(acc_GBR)\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "predicted = cross_val_predict(reg,X,y,cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result of GBR\n",
    "r2 = np.mean(r2)\n",
    "mape = np.mean(mape)\n",
    "mae = np.mean(mae)\n",
    "mse = np.mean(mse)\n",
    "acc = np.mean(acc)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction']='in'\n",
    "plt.rcParams['font.sans-serif']=['Times New Roman']\n",
    "plt.xticks(fontproperties = 'Times New Roman',fontsize=20)\n",
    "plt.yticks( fontproperties = 'Times New Roman',fontsize=20)\n",
    "plt.title('GBR', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "plt.xlabel('Calculated Value ', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "plt.ylabel('Predicted Value', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "# plt.legend(loc='lower right', prop={'family':'Times New Roman', 'size':16})\n",
    "plt.text(0,15,r'$R^{2}$ = '+ str(round(r2*10000)/10000),fontsize=20)\n",
    "plt.text(0,13.5,'mape = '+ str(round(mape*10000)/10000),fontsize=20)  \n",
    "plt.text(0,12,'mae = '+ str(round(mae*10000)/10000),fontsize=20)    \n",
    "plt.text(0,10.5,'mse = '+ str(round(mse*10000)/10000),fontsize=20)    \n",
    "plt.text(0,9,'acc = '+ str(round(acc*10000)/100) + '%',fontsize=20)\n",
    "plt.savefig('GBR.png',format = 'png', dpi = 600,bbox_inches='tight', transparent=True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of GPR\n",
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "        random_state=0).fit(X_train, y_train)\n",
    "r2=[]\n",
    "mape=[]\n",
    "mae = []\n",
    "mse = []\n",
    "acc = []\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    kernel = DotProduct() + WhiteKernel()\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "        random_state=0).fit(X_train, y_train)\n",
    "    pre = gpr.predict(X_test)\n",
    "    yyy=pre.reshape(len(y_test),1) - y_test\n",
    "    zzz = yyy / y_test\n",
    "    cnt = 0\n",
    "    for i in zzz:\n",
    "        if i < 0.05 and i > -0.05:\n",
    "            cnt += 1\n",
    "    acc_pre = cnt / len(zzz)\n",
    "    r2.append(r2_score(y_test,pre))\n",
    "    mape.append(mean_absolute_percentage_error(y_test,pre))\n",
    "    mae.append(mean_absolute_error(y_test,pre))\n",
    "    mse.append(mean_squared_error(y_test,pre))\n",
    "    acc.append(acc_pre)\n",
    "#     print(r2_score(y_test,gbr_pre))\n",
    "#     print(mean_absolute_percentage_error(y_test,gbr_pre))\n",
    "#     print(mean_absolute_error(y_test,gbr_pre))\n",
    "#     print(mean_squared_error(y_test,gbr_pre))\n",
    "#     print(acc_GBR)\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "predicted = cross_val_predict(gpr,X,y,cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.mean(r2)\n",
    "mape = np.mean(mape)\n",
    "mae = np.mean(mae)\n",
    "mse = np.mean(mse)\n",
    "acc = np.mean(acc)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction']='in'\n",
    "plt.rcParams['font.sans-serif']=['Times New Roman']\n",
    "plt.xticks(fontproperties = 'Times New Roman',fontsize=20)\n",
    "plt.yticks( fontproperties = 'Times New Roman',fontsize=20)\n",
    "plt.title('GPR', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "plt.xlabel('Calculated Value ', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "plt.ylabel('Predicted Value', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "# plt.legend(loc='lower right', prop={'family':'Times New Roman', 'size':16})\n",
    "plt.text(0,15,r'$R^{2}$ = '+ str(round(r2*10000)/10000),fontsize=20)\n",
    "plt.text(0,13.5,'mape = '+ str(round(mape*10000)/10000),fontsize=20)  \n",
    "plt.text(0,12,'mae = '+ str(round(mae*10000)/10000),fontsize=20)    \n",
    "plt.text(0,10.5,'mse = '+ str(round(mse*10000)/10000),fontsize=20)    \n",
    "plt.text(0,9,'acc = '+ str(round(acc*10000)/100) + '%',fontsize=20)\n",
    "plt.savefig('GPR.png',format = 'png', dpi = 600,bbox_inches='tight', transparent=True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of SVR\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "regr = make_pipeline(StandardScaler(),LinearSVR(random_state=0, tol=1e-5))\n",
    "regr.fit(X_train,y_train)\n",
    "svr_pre = regr.predict(X_test)\n",
    "\n",
    "r2=[]\n",
    "mape=[]\n",
    "mae = []\n",
    "mse = []\n",
    "acc = []\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    regr = make_pipeline(StandardScaler(),LinearSVR(random_state=0, tol=1e-5))\n",
    "    regr.fit(X_train,y_train)\n",
    "    pre = regr.predict(X_test)\n",
    "    yyy=pre.reshape(len(y_test),1) - y_test\n",
    "    zzz = yyy / y_test\n",
    "    cnt = 0\n",
    "    for i in zzz:\n",
    "        if i < 0.05 and i > -0.05:\n",
    "            cnt += 1\n",
    "    acc_pre = cnt / len(zzz)\n",
    "    r2.append(r2_score(y_test,pre))\n",
    "    mape.append(mean_absolute_percentage_error(y_test,pre))\n",
    "    mae.append(mean_absolute_error(y_test,pre))\n",
    "    mse.append(mean_squared_error(y_test,pre))\n",
    "    acc.append(acc_pre)\n",
    "#     print(r2_score(y_test,gbr_pre))\n",
    "#     print(mean_absolute_percentage_error(y_test,gbr_pre))\n",
    "#     print(mean_absolute_error(y_test,gbr_pre))\n",
    "#     print(mean_squared_error(y_test,gbr_pre))\n",
    "#     print(acc_GBR)\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "predicted = cross_val_predict(regr,X,y,cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.mean(r2)\n",
    "mape = np.mean(mape)\n",
    "mae = np.mean(mae)\n",
    "mse = np.mean(mse)\n",
    "acc = np.mean(acc)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction']='in'\n",
    "plt.rcParams['font.sans-serif']=['Times New Roman']\n",
    "plt.xticks(fontproperties = 'Times New Roman',fontsize=20)\n",
    "plt.yticks( fontproperties = 'Times New Roman',fontsize=20)\n",
    "\n",
    "plt.xlabel('Calculated Value ', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "plt.ylabel('Predicted Value', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "# plt.legend(loc='lower right', prop={'family':'Times New Roman', 'size':16})\n",
    "plt.text(0,15,r'$R^{2}$ = '+ str(round(r2*10000)/10000),fontsize=20)\n",
    "plt.text(0,13.5,'mape = '+ str(round(mape*10000)/10000),fontsize=20)  \n",
    "plt.text(0,12,'mae = '+ str(round(mae*10000)/10000),fontsize=20)    \n",
    "plt.text(0,10.5,'mse = '+ str(round(mse*10000)/10000),fontsize=20)    \n",
    "plt.text(0,9,'acc = '+ str(round(acc*10000)/100) + '%',fontsize=20)\n",
    "plt.title('SVR', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "plt.savefig('SVR.png',format = 'png', dpi = 600,bbox_inches='tight', transparent=True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of DTR\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_train,y_train)\n",
    "dtr_pre = regressor.predict(X_test)\n",
    "\n",
    "r2=[]\n",
    "mape=[]\n",
    "mae = []\n",
    "mse = []\n",
    "acc = []\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    regressor = DecisionTreeRegressor(random_state=0)\n",
    "    regressor.fit(X_train,y_train)\n",
    "    pre = regressor.predict(X_test)\n",
    "    yyy=pre.reshape(len(y_test),1) - y_test\n",
    "    zzz = yyy / y_test\n",
    "    cnt = 0\n",
    "    for i in zzz:\n",
    "        if i < 0.05 and i > -0.05:\n",
    "            cnt += 1\n",
    "    acc_pre = cnt / len(zzz)\n",
    "    r2.append(r2_score(y_test,pre))\n",
    "    mape.append(mean_absolute_percentage_error(y_test,pre))\n",
    "    mae.append(mean_absolute_error(y_test,pre))\n",
    "    mse.append(mean_squared_error(y_test,pre))\n",
    "    acc.append(acc_pre)\n",
    "#     print(r2_score(y_test,gbr_pre))\n",
    "#     print(mean_absolute_percentage_error(y_test,gbr_pre))\n",
    "#     print(mean_absolute_error(y_test,gbr_pre))\n",
    "#     print(mean_squared_error(y_test,gbr_pre))\n",
    "#     print(acc_GBR)\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "predicted = cross_val_predict(regressor,X,y,cv=kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.mean(r2)\n",
    "mape = np.mean(mape)\n",
    "mae = np.mean(mae)\n",
    "mse = np.mean(mse)\n",
    "acc = np.mean(acc)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction']='in'\n",
    "plt.rcParams['font.sans-serif']=['Times New Roman']\n",
    "plt.xticks(fontproperties = 'Times New Roman',fontsize=20)\n",
    "plt.yticks( fontproperties = 'Times New Roman',fontsize=20)\n",
    "\n",
    "plt.xlabel('Calculated Value ', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "plt.ylabel('Predicted Value', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "# plt.legend(loc='lower right', prop={'family':'Times New Roman', 'size':16})\n",
    "plt.text(0,15,r'$R^{2}$ = '+ str(round(r2*10000)/10000),fontsize=20)\n",
    "plt.text(0,13.5,'mape = '+ str(round(mape*10000)/10000),fontsize=20)  \n",
    "plt.text(0,12,'mae = '+ str(round(mae*10000)/10000),fontsize=20)    \n",
    "plt.text(0,10.5,'mse = '+ str(round(mse*10000)/10000),fontsize=20)    \n",
    "plt.text(0,9,'acc = '+ str(round(acc*10000)/100) + '%',fontsize=20)\n",
    "plt.title('DTR', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "\n",
    "# plt.legend(loc='lower right', prop={'family':'Times New Roman', 'size':16})\n",
    "\n",
    "plt.savefig('DTR.png',format = 'png', dpi = 600,bbox_inches='tight', transparent=True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of RFR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "regr = RandomForestRegressor()\n",
    "regr.fit(X_train,y_train)\n",
    "rfr_pre = regr.predict(X_test)\n",
    "\n",
    "r2=[]\n",
    "mape=[]\n",
    "mae = []\n",
    "mse = []\n",
    "acc = []\n",
    "for train_index,test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    regr = RandomForestRegressor()\n",
    "    regr.fit(X_train,y_train)\n",
    "    pre = regr.predict(X_test)\n",
    "    yyy=pre.reshape(len(y_test),1) - y_test\n",
    "    zzz = yyy / y_test\n",
    "    cnt = 0\n",
    "    for i in zzz:\n",
    "        if i < 0.05 and i > -0.05:\n",
    "            cnt += 1\n",
    "    acc_pre = cnt / len(zzz)\n",
    "    r2.append(r2_score(y_test,pre))\n",
    "    mape.append(mean_absolute_percentage_error(y_test,pre))\n",
    "    mae.append(mean_absolute_error(y_test,pre))\n",
    "    mse.append(mean_squared_error(y_test,pre))\n",
    "    acc.append(acc_pre)\n",
    "#     print(r2_score(y_test,gbr_pre))\n",
    "#     print(mean_absolute_percentage_error(y_test,gbr_pre))\n",
    "#     print(mean_absolute_error(y_test,gbr_pre))\n",
    "#     print(mean_squared_error(y_test,gbr_pre))\n",
    "#     print(acc_GBR)\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "predicted = cross_val_predict(regr,X,y,cv=kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.mean(r2)\n",
    "mape = np.mean(mape)\n",
    "mae = np.mean(mae)\n",
    "mse = np.mean(mse)\n",
    "acc = np.mean(acc)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction']='in'\n",
    "plt.rcParams['font.sans-serif']=['Times New Roman']\n",
    "plt.xticks(fontproperties = 'Times New Roman',fontsize=20)\n",
    "plt.yticks( fontproperties = 'Times New Roman',fontsize=20)\n",
    "\n",
    "plt.xlabel('Calculated Value ', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "plt.ylabel('Predicted Value', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "# plt.legend(loc='lower right', prop={'family':'Times New Roman', 'size':16})\n",
    "plt.text(0,15,r'$R^{2}$ = '+ str(round(r2*10000)/10000),fontsize=20)\n",
    "plt.text(0,13.5,'mape = '+ str(round(mape*10000)/10000),fontsize=20)  \n",
    "plt.text(0,12,'mae = '+ str(round(mae*10000)/10000),fontsize=20)    \n",
    "plt.text(0,10.5,'mse = '+ str(round(mse*10000)/10000),fontsize=20)    \n",
    "plt.text(0,9,'acc = '+ str(round(acc*10000)/100) + '%',fontsize=20)\n",
    "plt.title('RFR', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "\n",
    "plt.savefig('RFR.png',format = 'png', dpi = 600,bbox_inches='tight', transparent=True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of ANN\n",
    "# compare two different descriptor sets \n",
    "final_list = ['VF2', 'GXD', 'SVF', 'GMAXVX', 'GMINVX', 'GMAXVY', 'MEANCV', 'MPDV3', 'MPDM3', 'MINCV', 'GMAXVZ', 'MPDM2', 'D1', 'MPDV1', 'MCLZY2', 'MCLXZ2', 'MCLZX2', 'MCLXYZ2', 'MCLXZY2', 'MCLYZX2', 'GSDY', 'GSDX', 'MCLZ2', 'MCLY2', 'MCLX2', 'MCLXY2', 'MCLXZ1', 'MCLYZ1', 'MCLYZX1', 'MCLXZY1', 'MCLYX1', 'V1', 'SA1', 'SSA1', 'SA2', 'OMAXTL', 'CP', 'SIM2', 'LBS', 'OMEANTL', 'OMINTL', 'NOVEXD', 'NOVEYD', 'NOCC', 'SAE', 'SSAE', 'NOVS', 'SSAV', 'IT1', 'SIT1', 'EC62', 'L1', 'L2', 'PLV3', 'LBOD1', 'OD1', 'HBOD1', 'ST', 'SIM1', 'UBS', 'SorD', 'OD3', 'MAXCV', 'Mass', 'GMVX', 'GMINVY', 'D3', 'GSDZ', 'IM2']\n",
    "#final_list = ['VF2','POST']\n",
    "c_c = np.array(conduct[final_list])\n",
    "c_X = c_c\n",
    "c_y = c[:,131:132]\n",
    "c_X = preprocessing.scale(c_X)\n",
    "c_X_train_full, c_X_test, c_y_train_full, c_y_test = train_test_split(\n",
    "   c_X, c_y,random_state = 32, shuffle = True)\n",
    "c_X_train, c_X_valid, c_y_train, c_y_valid = train_test_split(\n",
    "    c_X_train_full, c_y_train_full,random_state = 32, shuffle = True)\n",
    "input_ = keras.layers.Input(shape=c_X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "d1 = 12\n",
    "d2 = 29\n",
    "d3 = 29\n",
    "input_ = keras.layers.Input(shape=c_X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(d1, kernel_regularizer=regularizers.l2(0.005),activation=LeakyReLU(alpha=0.3))(input_)\n",
    "hidden2 = keras.layers.Dense(d2, kernel_regularizer=regularizers.l2(0.005),activation=LeakyReLU(alpha=0.3))(hidden1)\n",
    "hidden3 = keras.layers.Dense(d3, kernel_regularizer=regularizers.l2(0.005),activation=LeakyReLU(alpha=0.3))(hidden2)\n",
    "concat = keras.layers.concatenate([input_, hidden2, hidden3])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model1 = keras.models.Model(inputs=[input_], outputs=[output])\n",
    "# if the loss does not decrease for 1000 times, the training will stop\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=1000, mode = 'min')\n",
    "model1.compile(loss='mape',optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08),metrics=['mse',r2])\n",
    "history1 = model1.fit(c_X_train, c_y_train, epochs=30000,verbose = 1,validation_data=(c_X_valid, c_y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5,shuffle=True, random_state=None)\n",
    "ann_pre = model1.predict(c_X_test)\n",
    "\n",
    "r2=[]\n",
    "mape=[]\n",
    "mae = []\n",
    "mse = []\n",
    "acc = []\n",
    "cal_val = []\n",
    "pre_val = []\n",
    "for train_index,test_index in kf.split(c_X):\n",
    "    c_X_train, c_X_test = c_X[train_index], c_X[test_index]\n",
    "    c_y_train, c_y_test = c_y[train_index], c_y[test_index]\n",
    "    pre = model1.predict(c_X_test)\n",
    "    yyy=pre.reshape(len(c_y_test),1) - c_y_test\n",
    "    zzz = yyy / c_y_test\n",
    "    cnt = 0\n",
    "    for i in zzz:\n",
    "        if i < 0.05 and i > -0.05:\n",
    "            cnt += 1\n",
    "    acc_pre = cnt / len(zzz)\n",
    "    r2.append(r2_score(c_y_test,pre))\n",
    "    mape.append(mean_absolute_percentage_error(c_y_test,pre))\n",
    "    mae.append(mean_absolute_error(c_y_test,pre))\n",
    "    mse.append(mean_squared_error(c_y_test,pre))\n",
    "    acc.append(acc_pre)\n",
    "    cal_val.append(c_y_test)\n",
    "    pre_val.append(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.mean(r2)\n",
    "mape = np.mean(mape)\n",
    "mae = np.mean(mae)\n",
    "mse = np.mean(mse)\n",
    "acc = np.mean(acc)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.scatter(cal_re,pre_re, edgecolors=(0, 0, 0))\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction']='in'\n",
    "plt.rcParams['font.sans-serif']=['Times New Roman']\n",
    "plt.xticks(fontproperties = 'Times New Roman',fontsize=20)\n",
    "plt.yticks( fontproperties = 'Times New Roman',fontsize=20)\n",
    "\n",
    "plt.xlabel('Calculated Value ', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "plt.ylabel('Predicted Value', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "# plt.legend(loc='lower right', prop={'family':'Times New Roman', 'size':16})\n",
    "plt.text(0,15,r'$R^{2}$ = '+ str(round(r2*10000)/10000),fontsize=20)\n",
    "plt.text(0,13.5,'mape = '+ str(round(mape*10000)/10000),fontsize=20)  \n",
    "plt.text(0,12,'mae = '+ str(round(mae*10000)/10000),fontsize=20)    \n",
    "plt.text(0,10.5,'mse = '+ str(round(mse*10000)/10000),fontsize=20)    \n",
    "plt.text(0,9,'acc = '+ str(round(acc*10000)/100) + '%',fontsize=20)\n",
    "plt.title('ANN', fontdict={'family' : 'Times New Roman', 'size':20})\n",
    "\n",
    "# plt.legend(loc='lower right', prop={'family':'Times New Roman', 'size':16})\n",
    "\n",
    "plt.savefig('ANN.png',format = 'png', dpi = 600,bbox_inches='tight', transparent=True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pre = model1.predict(c_X_test)\n",
    "yyy=ann_pre.reshape(len(c_y_test),1) - c_y_test\n",
    "zzz = yyy / c_y_test\n",
    "cnt = 0\n",
    "for i in zzz:\n",
    "    if i < 0.05 and i > -0.05:\n",
    "        cnt += 1\n",
    "acc_ANN = cnt / len(zzz)\n",
    "print(r2_score(c_y_test,ann_pre))\n",
    "print(mean_absolute_percentage_error(c_y_test,ann_pre))\n",
    "print(mean_absolute_error(c_y_test,ann_pre))\n",
    "print(mean_squared_error(c_y_test,ann_pre))\n",
    "print(acc_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scatter diagram of the actual value and the predicted value of ANN\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.figure(figsize=(8, 4), dpi=600)\n",
    "plt.plot(range(len(c_y_test)), c_y_test, 'o',c='r',label='Test Sample')\n",
    "plt.plot(range(len(ann_pre)), ann_pre, '<',c='b',label='Prediction')\n",
    "plt.legend()\n",
    "plt.xlabel('Test Sample Number',fontsize = 15) \n",
    "plt.ylabel('Predicted TC by ANN',fontsize = 15) \n",
    "plt.savefig('cosandian' + '.png', format='png', bbox_inches='tight', transparent=True,dpi=600) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
